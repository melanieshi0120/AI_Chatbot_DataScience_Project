{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refereces:\n",
    "- https://www.google.com/search?q=how+to+use+tkinter+to+create+a+chatbot+in+python&oq=how+to+use+tkinter+to+create+a+chatbot&aqs=chrome.1.69i57j33.44216j0j4&sourceid=chrome&ie=UTF-8#kpvalbx=_VJZOX5znAquIytMPkfS2iAE37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages/libraries first \n",
    "# !pip install pyttsx3\n",
    "# !pip install wikipedia\n",
    "# !pip install SpeechRecognition\n",
    "# !pip install pygame\n",
    "# !pip install pyown\n",
    "# conda install pyaudio # please import this via ternimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run this first if you want to run part 2\n",
    "# from tkinter import *\n",
    "# root=Tk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "### import libraries for voice output\n",
    "# source: https://www.codementor.io/@edwardzionsaji/simple-voice-enabled-chat-bot-in-python-kt2qi5oke\n",
    "import datetime\n",
    "import webbrowser\n",
    "import pyttsx3\n",
    "import wikipedia\n",
    "from pygame import mixer\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and calibrate the text to speech engine.\n",
    "# Now we need to set the voice rate, engine, etc.\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[10].id)\n",
    "volume = engine.getProperty('volume')\n",
    "engine.setProperty('volume', 10.0)\n",
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate - 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "df=pd.read_csv(\"chatbot_data_Q&A - basic_python_questions.csv\").dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()# check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data?</td>\n",
       "      <td>Based on the definition from google : facts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is data science?</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is big data?</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of big data</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question                                             answer\n",
       "0                    data?  Based on the definition from google : facts an...\n",
       "1    what is data science?  Data science is an inter-disciplinary field th...\n",
       "2             data science  Data science is an inter-disciplinary field th...\n",
       "3        what is big data?  In the data science domain, big data usually r...\n",
       "4  definition of big data   In the data science domain, big data usually r..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()# take a look at the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some uncompleted questions\n",
    "# if a question or answers end with \":\" \n",
    "questions=[]\n",
    "for i in df.question:\n",
    "    if i[-1]==\":\":\n",
    "        questions.append(None)\n",
    "    else:\n",
    "        questions.append(i)\n",
    "        \n",
    "        \n",
    "# remove some uncompleted answers\n",
    "answers=[]\n",
    "for i in df.answer:\n",
    "    if i[-1]==\":\":\n",
    "        answers.append(None)\n",
    "    else:\n",
    "        answers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange a little bit\n",
    "df['answer']=answers\n",
    "df['question']=questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data?</td>\n",
       "      <td>Based on the definition from google : facts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is data science?</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is big data?</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of big data</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question                                             answer\n",
       "0                    data?  Based on the definition from google : facts an...\n",
       "1    what is data science?  Data science is an inter-disciplinary field th...\n",
       "2             data science  Data science is an inter-disciplinary field th...\n",
       "3        what is big data?  In the data science domain, big data usually r...\n",
       "4  definition of big data   In the data science domain, big data usually r..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna(axis=0).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r'[-()\\\"#/@;:<>{}`+=~|.!?,]\\|', \"\", text)\n",
    "    text=text.replace(\"[\\'\",\"\").replace(\"\\n\",\" \").replace(\"']\",\" \").replace('[\"',\"\").replace('\"]',\"\").replace(\"it\\'s\",\"it's \").replace(\"\\', \\'\",\"\")\n",
    "    text=text.replace(\"\\',\",\"\").replace(\"it\\'s\",\"it is \").replace(\"it\\\\\\'s\",\"it is\").replace(\" \\\\\",\" \")\n",
    "    text=text.replace('\",',\" \").replace(\"\\',\",\"\").replace( \":\\',\",\"\").replace(\"here\\'s\",\"\").replace(\":\",\"\").replace(',\"',\"\")\n",
    "    text=text.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'s\",\"'s\")\n",
    "    text=re.sub(r\"let's\", \"let us\", text)\n",
    "    text = text.replace(\"\\'s\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#declare answers and questions\n",
    "questions=df.question\n",
    "answers=df.answer\n",
    "# Cleaning the questions\n",
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "# Cleaning the answers\n",
    "clean_answers = []\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definition of data visualization, what is data visualization?',\n",
       " 'what tools do professional data scientists use? ',\n",
       " 'mian tools in data science',\n",
       " 'how to install git',\n",
       " 'what is conda and anaconda?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list contains  punctuation\n",
    "#sw_list = stopwords.words('english')\n",
    "sw_list = list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©',\n",
    "'said',\"'s\", \"also\",'one',\"n't\",'com', '-', '–','--' ,\n",
    "'—', '_']\n",
    "sw_set = set(sw_list)\n",
    "\n",
    "# tokenization\n",
    "def process_data(string):\n",
    "    tokens = nltk.word_tokenize(string) # tokenization\n",
    "    punctuation_removed = [token.lower() for token in tokens if token.lower() not in sw_set]\n",
    "    return punctuation_removed\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "# create a function stemming() and loop through each word in a review\n",
    "def stemming(string):\n",
    "    stemmed_string=[]\n",
    "    for w in string:\n",
    "        stemmed_string.append(ps.stem(w))\n",
    "    return stemmed_string\n",
    "\n",
    "# import libraries\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# create a function  and loop through each word in  a review\n",
    "def lemmatization(string):\n",
    "    lemma_list=[]\n",
    "    for word in string:\n",
    "        lemma_word=lemmatizer.lemmatize(word,pos='v') \n",
    "        lemma_list.append(lemma_word)\n",
    "    return lemma_list\n",
    "\n",
    "# Conbime all functions above and obtian cleaned text data \n",
    "def data_preprocessing(text_data):\n",
    "    #tokenization, stop words removal, punctuation marks removel\n",
    "    processed_string=list(map(process_data,text_data))\n",
    "    # stemming\n",
    "    stemming_string=list(map(stemming,processed_string))\n",
    "    # lemmatization\n",
    "    lemma_string=list(map(lemmatization,stemming_string))\n",
    "    \n",
    "    return lemma_string\n",
    "\n",
    "# create a function of NLP for single line\n",
    "def NLP(text):\n",
    "    cleaned_question=clean_text(text)\n",
    "    processed_question=process_data(cleaned_question)\n",
    "    stemming_question=stemming(processed_question)\n",
    "    lemma_question=lemmatization(stemming_question)\n",
    "    return lemma_question\n",
    "\n",
    "# List of Greeting , goodbye and thank you you are welcome\n",
    "greeting=['hey', 'hi', 'hello', 'hey man', 'hi how are you', 'how are you','how is it going', \n",
    "          'nice to meet you', 'how are you doing', 'what is up', 'what is new', \n",
    "          'what is going on', 'how is everything', 'how are things', 'how is life', \n",
    "          'how is your day', 'how is your day going', 'good to see you', 'nice to see you']\n",
    "goodbye=[\"see you\",\"bye\",\"byebye\",\"goodbye\"]\n",
    "\n",
    "thankyou=[\"thanks\",\"thank you\", \"thank you very much\"]\n",
    "yourwelcome=[\"you are welcome ^.^\",\"my pleasure!\",\"I am happy to help you!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function above to process the data \n",
    "cleaned_questions=data_preprocessing(clean_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPlease run part 1 and part 2 individually.\\nIf you run part 2 first please \" comment\" part 1 then run part 2\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=============================================================================================================#\n",
    "'''\n",
    "Please run part 1 and part 2 individually.\n",
    "If you run part 2 first please \" comment\" part 1 then run part 2\n",
    "'''\n",
    "#=============================================================================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One - With Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# function - chatbot\n",
    "def chatbot(question):\n",
    "   \n",
    "    if  question.strip().lower() in greeting:\n",
    "        answer=random.choice(greeting).capitalize()\n",
    "        return  answer\n",
    "    elif  question.strip().lower() in goodbye:\n",
    "        answer=random.choice(goodbye)\n",
    "        return answer\n",
    "        \n",
    "    elif question.strip().lower() in thankyou:\n",
    "        answer= random.choice(yourwelcome).capitalize()\n",
    "        return  answer\n",
    "    else:\n",
    "        # NLP\n",
    "        pro_text= NLP(question)\n",
    "\n",
    "        # to find which row has intersection with the words from question you asked\n",
    "        # which means to find the who have common elements between your question and the data\n",
    "        inter_list=[]\n",
    "        for i in cleaned_questions:\n",
    "            if (set(pro_text) & set(i)):\n",
    "                inter_list.append((list(set(pro_text) & set(i)),cleaned_questions.index(i)))\n",
    "\n",
    "        # remove stop words  \n",
    "        new_inter_list=[]\n",
    "        for i in range(len(inter_list)):\n",
    "            for j in inter_list[i][0]:\n",
    "                if j not in stopwords.words('english'):\n",
    "                    new_inter_list.append(inter_list[i])\n",
    "\n",
    "        # find the max length of common elements\n",
    "        lengths=[len(new_inter_list[i][0]) for i in range(len(new_inter_list)) ]\n",
    "        \n",
    "\n",
    "        indexes=[]\n",
    "        if len(lengths)>0:\n",
    "            max_length=max(lengths)\n",
    "            # find all the index whose correspondiong question data have the most common elements\n",
    "            for i in range(len(new_inter_list)):\n",
    "                if len(new_inter_list[i][0])==max_length:\n",
    "                    indexes.append(new_inter_list[i][1])\n",
    "                    # to find ratios that the keys in a sentence\n",
    "            ratios=[]\n",
    "            for i in list(set(indexes)):\n",
    "                ratio=len(pro_text)/len(questions.iloc[i])\n",
    "                ratios.append((ratio,i))\n",
    "                \n",
    "            final_indexes=[]\n",
    "            if [ratios[i][0] for i in range(len(ratios))]!=[]:\n",
    "                max_ratios=max([ratios[i][0] for i in range(len(ratios))])\n",
    "\n",
    "                for i in range(len(ratios)):\n",
    "                    if ratios[i][0]==max_ratios:\n",
    "                        final_indexes.append(ratios[i][1])\n",
    "            else:\n",
    "                return \"Sorry, I don't know. I need to learn more!\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if len(final_indexes)>0:\n",
    "                # to randomly find an answer based on the index\n",
    "                answer_index=random.choice(final_indexes)\n",
    "                return answers.iloc[answer_index]\n",
    " \n",
    "\n",
    "            else:\n",
    "               return \"Sorry, I don't know. I need to learn more!\"  \n",
    "                    \n",
    "        else:\n",
    "            return \"Sorry, I don't know. I need to learn more!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============# Hi There my name is Chacha. Let's Talk #=============\n",
      "You: hi \n",
      "Chacha: Hey\n",
      "\n",
      "You: how are you\n",
      "Chacha: Good to see you\n",
      "\n",
      "You: how to select a column from dataframe?\n",
      "Chacha: # if you want to select a specific column you can use this code:\n",
      "df[\"column_name\"] \n",
      "\n",
      "You: how to make scatter plot?\n",
      "Chacha: # import libraries\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy import stats\n",
      "sns.set(color_codes=True)\n",
      "#Plotting univariate distributions\n",
      "#The most convenient way to take a quick look at a univariate distribution in seaborn is the distplot() function. By default, this will draw a histogram and fit a kernel density estimate (KDE).\n",
      "\n",
      "x = np.random.normal(size=100)\n",
      "sns.distplot(x);\n",
      "\n",
      "\n",
      "You: how to make a pivot table?\n",
      "Chacha: # code and parameter\n",
      "pandas.pivot_table(data, values=None, index=None, columns=None, aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All', observed=False)\n",
      "\n",
      "# Examples\n",
      "import pandas as pd\n",
      "df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "                         \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "                   \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "                         \"one\", \"one\", \"two\", \"two\"],\n",
      "                   \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "                         \"small\", \"large\", \"small\", \"small\",\n",
      "                         \"large\"],\n",
      "                   \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "                   \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      "df\n",
      ">>>\n",
      "     A    B      C  D  E\n",
      "0  foo  one  small  1  2\n",
      "1  foo  one  large  2  4\n",
      "2  foo  one  large  2  5\n",
      "3  foo  two  small  3  5\n",
      "4  foo  two  small  3  6\n",
      "5  bar  one  large  4  6\n",
      "6  bar  one  small  5  8\n",
      "7  bar  two  small  6  9\n",
      "8  bar  two  large  7  9\n",
      "\n",
      "#This first example aggregates values by taking the sum.\n",
      "\n",
      "table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "                    columns=['C'], aggfunc=np.sum)\n",
      "table\n",
      ">>>\n",
      "C        large  small\n",
      "A   B\n",
      "bar one    4.0    5.0\n",
      "      two    7.0    6.0\n",
      "foo one    4.0    1.0\n",
      "      two    NaN    6.0\n",
      "\n",
      "\n",
      "You: thank you \n",
      "Chacha: My pleasure!\n",
      "\n",
      "You: bye\n",
      "Chacha: byebye\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=============# Hi There my name is Chacha. Let's Talk #=============\")\n",
    "\n",
    "while(True): \n",
    "    question = input(\"You: \")\n",
    "    if question.strip().lower() in goodbye:\n",
    "        answer=random.choice(goodbye)\n",
    "        print(\"Chacha: \"+answer+\"\\n\") \n",
    "        engine.say(answer)\n",
    "        engine.runAndWait()\n",
    "        break\n",
    "    else:\n",
    "        pro_text= NLP(question)\n",
    "        answer=chatbot(question)\n",
    "        print(\"Chacha: \"+answer+\"\\n\")\n",
    "        engine.say(answer)\n",
    "        engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two - chatbot with interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def func(event):\n",
    "     print(\"You hit return.\")\n",
    "def send(event=None):\n",
    "    send=\"You: \"+e.get()\n",
    "    txt.insert(END,\"\\n\"+send)\n",
    "    txt.see(END+\"\\n\")\n",
    "    \n",
    "    if e.get().strip().lower() in goodbye:\n",
    "        byebye=\"Byebye! see you next time! \"\n",
    "        txt.insert(END,\"\\n\"+\"Chacha: \"+byebye+\"\\n\")  \n",
    "        e.delete(0,END)\n",
    "        txt.see(END)\n",
    "\n",
    "    elif  e.get().strip().lower() in greeting:\n",
    "        answer=random.choice(greeting).capitalize()\n",
    "        txt.insert(END,\"\\n\"+\"Chacha: \"+ answer+\"\\n\")\n",
    "        e.delete(0,END)\n",
    "        txt.see(END)\n",
    "\n",
    "\n",
    "    elif e.get().strip().lower() in thankyou:\n",
    "        txt.insert(END,\"\\n\"+\"Chacha: \"+ random.choice(yourwelcome).capitalize()+\"\\n\")\n",
    "        e.delete(0,END)\n",
    "        txt.see(END)\n",
    "    else:\n",
    "        # NLP\n",
    "        pro_text= NLP(e.get())\n",
    "        # to find which row has intersection with the words from question you asked\n",
    "        # which means to find the who have common elements between your question and the data\n",
    "        inter_list=[]\n",
    "        for i in cleaned_questions:\n",
    "            if (set(pro_text) & set(i)):\n",
    "                inter_list.append((list(set(pro_text) & set(i)),cleaned_questions.index(i)))         \n",
    "\n",
    "        # remove stop words  \n",
    "        new_inter_list=[]\n",
    "        for i in range(len(inter_list)):\n",
    "            for j in inter_list[i][0]:\n",
    "                if j not in stopwords.words('english'):\n",
    "                    new_inter_list.append(inter_list[i])\n",
    "\n",
    "        # find the max length of common elements\n",
    "        lengths=[len(new_inter_list[i][0]) for i in range(len(new_inter_list)) ]\n",
    "        indexes=[]\n",
    "        if len(lengths)>0:\n",
    "            max_length=max(lengths)\n",
    "            # find all the index whose correspondiong question data have the most common elements\n",
    "            for i in range(len(new_inter_list)):\n",
    "                if len(new_inter_list[i][0])==max_length:\n",
    "                    indexes.append(new_inter_list[i][1])\n",
    "                    # to find ratios that the keys in a sentence\n",
    "            ratios=[]\n",
    "            for i in list(set(indexes)):\n",
    "                ratio=len(pro_text)/len(questions.iloc[i])\n",
    "                ratios.append((ratio,i))\n",
    "            final_indexes=[]\n",
    "            if [ratios[i][0] for i in range(len(ratios))]!=[]:\n",
    "                max_ratios=max([ratios[i][0] for i in range(len(ratios))])\n",
    "\n",
    "                for i in range(len(ratios)):\n",
    "                    if ratios[i][0]==max_ratios:\n",
    "                        final_indexes.append(ratios[i][1])\n",
    "            else:\n",
    "                txt.insert(END,\"\\n\"+\"Chacha: \"+\"Sorry, I don't know. I need to learn more!\"+\"\\n\")\n",
    "                e.delete(0,END)\n",
    "                txt.see(END)\n",
    "\n",
    "\n",
    "\n",
    "            if len(final_indexes)>0:\n",
    "                # to randomly find an answer based on the index\n",
    "                answer_index=random.choice(final_indexes)\n",
    "                txt.insert(END,\"\\n\"+ \"Chacha: \"+ answers.iloc[answer_index]+\"\\n\")\n",
    "                e.delete(0,END)\n",
    "                txt.see(END)\n",
    "            else:\n",
    "                txt.insert(END,\"\\n\"+\"Chacha: \"+\"Sorry, I don't know. I need to learn more!\"+\"\\n\")\n",
    "                e.delete(0,END)\n",
    "                txt.see(END)        \n",
    "                    \n",
    "        else:\n",
    "            txt.insert(END,\"\\n\"+\"Chacha: \"+\"Sorry, I don't know. I need to learn more!\"+\"\\n\")\n",
    "            e.delete(0,END)\n",
    "            txt.see(END)\n",
    "\n",
    " \n",
    "    e.delete(0,END)\n",
    "    \n",
    "root=Tk() \n",
    "root.bind('<Return>', send)    \n",
    "txt=Text(root)\n",
    "txt.grid(row=0,column=0,columnspan=2)\n",
    "e=Entry(root,width=60)\n",
    "send=Button(root,text=\"Send\",command=send,fg='black', bg='white').grid(row=1,column=1)\n",
    "e.grid(row=1,column=0)\n",
    "root.title(\"Mini Chatbot for Data Science\")\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
