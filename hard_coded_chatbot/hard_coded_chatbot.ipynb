{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages/libraries first \n",
    "# !pip install pyttsx3\n",
    "# !pip install wikipedia\n",
    "# !pip install SpeechRecognition\n",
    "# !pip install pygame\n",
    "# !pip install pyown\n",
    "# conda install pyaudio # please import this via ternimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from nltk.corpus import stopwords\n",
    "import re, string\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "### import libraries for voice output\n",
    "# source: https://www.codementor.io/@edwardzionsaji/simple-voice-enabled-chat-bot-in-python-kt2qi5oke\n",
    "import datetime\n",
    "import webbrowser\n",
    "import pyttsx3\n",
    "import wikipedia\n",
    "from pygame import mixer\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and calibrate the text to speech engine.\n",
    "# Now we need to set the voice rate, engine, etc.\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[10].id) # voices[0] American accent , voices[1] british accent\n",
    "volume = engine.getProperty('volume')\n",
    "engine.setProperty('volume', 10.0) \n",
    "rate = engine.getProperty('rate')\n",
    "engine.setProperty('rate', rate - 25) # you can change the speed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "df=pd.read_csv(\"chatbot_data_Q&A - basic_python_questions.csv\").dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    0\n",
       "answer      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()# check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data?</td>\n",
       "      <td>Based on the definition from google : facts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is data science?</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is big data?</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of big data</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question                                             answer\n",
       "0                    data?  Based on the definition from google : facts an...\n",
       "1    what is data science?  Data science is an inter-disciplinary field th...\n",
       "2             data science  Data science is an inter-disciplinary field th...\n",
       "3        what is big data?  In the data science domain, big data usually r...\n",
       "4  definition of big data   In the data science domain, big data usually r..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()# take a look at the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some uncompleted questions\n",
    "# if a question or answers end with \":\" \n",
    "questions=[]\n",
    "for i in df.question:\n",
    "    if i[-1]==\":\":\n",
    "        questions.append(None)\n",
    "    else:\n",
    "        questions.append(i)\n",
    "        \n",
    "        \n",
    "# remove some uncompleted answers\n",
    "answers=[]\n",
    "for i in df.answer:\n",
    "    if i[-1]==\":\":\n",
    "        answers.append(None)\n",
    "    else:\n",
    "        answers.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange a little bit\n",
    "df['answer']=answers\n",
    "df['question']=questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data?</td>\n",
       "      <td>Based on the definition from google : facts an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is data science?</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data science</td>\n",
       "      <td>Data science is an inter-disciplinary field th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is big data?</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>definition of big data</td>\n",
       "      <td>In the data science domain, big data usually r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  question                                             answer\n",
       "0                    data?  Based on the definition from google : facts an...\n",
       "1    what is data science?  Data science is an inter-disciplinary field th...\n",
       "2             data science  Data science is an inter-disciplinary field th...\n",
       "3        what is big data?  In the data science domain, big data usually r...\n",
       "4  definition of big data   In the data science domain, big data usually r..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.dropna(axis=0).copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)\n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text)\n",
    "    text = re.sub(r\"how's\", \"how is\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"n't\", \" not\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"can't\", \"cannot\", text)\n",
    "    text = re.sub(r'[-()\\\"#/@;:<>{}`+=~|.!?,]\\|', \"\", text)\n",
    "    text=text.replace(\"[\\'\",\"\").replace(\"\\n\",\" \").replace(\"']\",\" \").replace('[\"',\"\").replace('\"]',\"\").replace(\"it\\'s\",\"it's \").replace(\"\\', \\'\",\"\")\n",
    "    text=text.replace(\"\\',\",\"\").replace(\"it\\'s\",\"it is \").replace(\"it\\\\\\'s\",\"it is\").replace(\" \\\\\",\" \")\n",
    "    text=text.replace('\",',\" \").replace(\"\\',\",\"\").replace( \":\\',\",\"\").replace(\"here\\'s\",\"\").replace(\":\",\"\").replace(',\"',\"\")\n",
    "    text=text.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'s\",\"'s\")\n",
    "    text=re.sub(r\"let's\", \"let us\", text)\n",
    "    text = text.replace(\"\\'s\", \"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#declare answers and questions\n",
    "questions=df.question\n",
    "answers=df.answer\n",
    "# Cleaning the questions\n",
    "clean_questions = []\n",
    "for question in questions:\n",
    "    clean_questions.append(clean_text(question))\n",
    "# Cleaning the answers\n",
    "clean_answers = []\n",
    "for answer in answers:\n",
    "    clean_answers.append(clean_text(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['definition of data visualization, what is data visualization?',\n",
       " 'what tools do professional data scientists use? ',\n",
       " 'mian tools in data science',\n",
       " 'how to install git',\n",
       " 'what is conda and anaconda?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_questions[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list contains  punctuation\n",
    "#sw_list = stopwords.words('english')\n",
    "sw_list = list(string.punctuation)\n",
    "sw_list += [\"''\", '\"\"', '...', '``', '’', '“', '’', '”', '‘', '‘',\"'\", '©',\n",
    "'said',\"'s\", \"also\",'one',\"n't\",'com', '-', '–','--' ,\n",
    "'—', '_']\n",
    "sw_set = set(sw_list)\n",
    "\n",
    "# tokenization\n",
    "def process_data(string):\n",
    "    tokens = nltk.word_tokenize(string) # tokenization\n",
    "    punctuation_removed = [token.lower() for token in tokens if token.lower() not in sw_set]\n",
    "    return punctuation_removed\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "# create a function stemming() and loop through each word in a review\n",
    "def stemming(string):\n",
    "    stemmed_string=[]\n",
    "    for w in string:\n",
    "        stemmed_string.append(ps.stem(w))\n",
    "    return stemmed_string\n",
    "\n",
    "# import libraries\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# create a function  and loop through each word in  a review\n",
    "def lemmatization(string):\n",
    "    lemma_list=[]\n",
    "    for word in string:\n",
    "        lemma_word=lemmatizer.lemmatize(word,pos='v') \n",
    "        lemma_list.append(lemma_word)\n",
    "    return lemma_list\n",
    "\n",
    "# Conbime all functions above and obtian cleaned text data \n",
    "def data_preprocessing(text_data):\n",
    "    #tokenization, stop words removal, punctuation marks removel\n",
    "    processed_string=list(map(process_data,text_data))\n",
    "    # stemming\n",
    "    stemming_string=list(map(stemming,processed_string))\n",
    "    # lemmatization\n",
    "    lemma_string=list(map(lemmatization,stemming_string))\n",
    "    \n",
    "    return lemma_string\n",
    "\n",
    "# create a function of NLP for single line\n",
    "def NLP(text):\n",
    "    cleaned_question=clean_text(text)\n",
    "    processed_question=process_data(cleaned_question)\n",
    "    stemming_question=stemming(processed_question)\n",
    "    lemma_question=lemmatization(stemming_question)\n",
    "    return lemma_question\n",
    "\n",
    "# List of Greeting , goodbye and thank you you are welcome\n",
    "greeting=['hey', 'hi', 'hello', 'hey man', 'hi how are you', 'how are you','how is it going', \n",
    "          'nice to meet you', 'how are you doing', 'what is up', 'what is new', \n",
    "          'what is going on', 'how is everything', 'how are things', 'how is life', \n",
    "          'how is your day', 'how is your day going', 'good to see you', 'nice to see you']\n",
    "goodbye=[\"see you\",\"bye\",\"byebye\",\"goodbye\"]\n",
    "\n",
    "thankyou=[\"thanks\",\"thank you\", \"thank you very much\"]\n",
    "yourwelcome=[\"you are welcome ^.^\",\"my pleasure!\",\"I am happy to help you!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the function above to process the data \n",
    "cleaned_questions=data_preprocessing(clean_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# function - chatbot\n",
    "def chatbot(question):\n",
    "   \n",
    "    if  question.strip().lower() in greeting:\n",
    "        answer=random.choice(greeting).capitalize()\n",
    "        return  answer\n",
    "    elif  question.strip().lower() in goodbye:\n",
    "        answer=random.choice(goodbye)\n",
    "        return answer\n",
    "        \n",
    "    elif question.strip().lower() in thankyou:\n",
    "        answer= random.choice(yourwelcome).capitalize()\n",
    "        return  answer\n",
    "    else:\n",
    "        # NLP\n",
    "        pro_text= NLP(question)\n",
    "\n",
    "        # to find which row has intersection with the words from question you asked\n",
    "        # which means to find the who have common elements between your question and the data\n",
    "        inter_list=[]\n",
    "        for i in cleaned_questions:\n",
    "            if (set(pro_text) & set(i)):\n",
    "                inter_list.append((list(set(pro_text) & set(i)),cleaned_questions.index(i)))\n",
    "\n",
    "        # remove stop words  \n",
    "        new_inter_list=[]\n",
    "        for i in range(len(inter_list)):\n",
    "            for j in inter_list[i][0]:\n",
    "                if j not in stopwords.words('english'):\n",
    "                    new_inter_list.append(inter_list[i])\n",
    "\n",
    "        # find the max length of common elements\n",
    "        lengths=[len(new_inter_list[i][0]) for i in range(len(new_inter_list)) ]\n",
    "        \n",
    "\n",
    "        indexes=[]\n",
    "        if len(lengths)>0:\n",
    "            max_length=max(lengths)\n",
    "            # find all the index whose correspondiong question data have the most common elements\n",
    "            for i in range(len(new_inter_list)):\n",
    "                if len(new_inter_list[i][0])==max_length:\n",
    "                    indexes.append(new_inter_list[i][1])\n",
    "                    # to find ratios that the keys in a sentence\n",
    "            ratios=[]\n",
    "            for i in list(set(indexes)):\n",
    "                ratio=len(pro_text)/len(questions.iloc[i])\n",
    "                ratios.append((ratio,i))\n",
    "                \n",
    "            final_indexes=[]\n",
    "            if [ratios[i][0] for i in range(len(ratios))]!=[]:\n",
    "                max_ratios=max([ratios[i][0] for i in range(len(ratios))])\n",
    "\n",
    "                for i in range(len(ratios)):\n",
    "                    if ratios[i][0]==max_ratios:\n",
    "                        final_indexes.append(ratios[i][1])\n",
    "            else:\n",
    "                return \"Sorry, I don't know. I need to learn more!\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            if len(final_indexes)>0:\n",
    "                # to randomly find an answer based on the index\n",
    "                answer_index=random.choice(final_indexes)\n",
    "                return answers.iloc[answer_index]\n",
    " \n",
    "\n",
    "            else:\n",
    "               return \"Sorry, I don't know. I need to learn more!\"  \n",
    "                    \n",
    "        else:\n",
    "            return \"Sorry, I don't know. I need to learn more!\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part One - With Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============# Hi There my name is Chacha. Let's Talk #=============\n",
      "You: hi\n",
      "Chacha: How is it going\n",
      "\n",
      "You: bye\n",
      "Chacha: byebye\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=============# Hi There my name is Chacha. Let's Talk #=============\")\n",
    "while(True): \n",
    "    question = input(\"You: \")\n",
    "    if question.strip().lower() in goodbye:\n",
    "        answer=random.choice(goodbye)\n",
    "        print(\"Chacha: \"+answer+\"\\n\")\n",
    "        engine.say(answer)\n",
    "        engine.runAndWait()\n",
    "        break\n",
    "    else:\n",
    "        answer=chatbot(question)\n",
    "        print(\"Chacha: \"+answer+\"\\n\")\n",
    "        engine.say(answer)\n",
    "        engine.runAndWait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part Two - chatbot with interface (basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part is created based on the packages - tkinter\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5396fa3ec67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#     engine.runAndWait()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Return>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tk' is not defined"
     ]
    }
   ],
   "source": [
    "def func(event):\n",
    "     print(\"You hit return.\")\n",
    "def send(event=None):\n",
    "    send=\"You: \"+e.get()\n",
    "    txt.insert(END,\"\\n\"+send)\n",
    "    txt.see(END+\"\\n\")\n",
    "    \n",
    "    answer=chatbot(e.get())\n",
    "    txt.insert(END,\"\\n\"+\"Chacha: \"+answer+\"\\n\")  \n",
    "    e.delete(0,END)\n",
    "#     engine.say(answer) # this part is to add voice function \n",
    "#     engine.runAndWait()\n",
    "    \n",
    "root=Tk() \n",
    "root.bind('<Return>', send)    \n",
    "txt=Text(root)\n",
    "txt.grid(row=0,column=0,columnspan=2)\n",
    "e=Entry(root,width=60)\n",
    "send=Button(root,text=\"Send\",command=send,fg='black', bg='white').grid(row=1,column=1)\n",
    "e.grid(row=1,column=0)\n",
    "root.title(\"Mini Chatbot for Data Science\")\n",
    "photo = PhotoImage(file = \"chatbot.ico\")\n",
    "root.iconphoto(photo)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
